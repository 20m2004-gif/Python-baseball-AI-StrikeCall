{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27343546-6a9b-4431-96ca-000300f875ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル読み込み中...: runs/detect/train9/weights/best.pt\n",
      "CSV読み込み中: Label.csv\n",
      "正解データを 150 件読み込みました。\n",
      "対象動画数: 150本\n",
      "------------------------------------------------------------\n",
      "File   | AI Pred    | Correct    | Result\n",
      "------------------------------------------------------------\n",
      "1      | STRIKE     | STRIKE     | OK\n",
      "2      | STRIKE     | STRIKE     | OK\n",
      "3      | BALL       | BALL       | OK\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 267\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# AIによる判定\u001b[39;00m\n\u001b[32m    266\u001b[39m judge = BatchJudge(shared_model)\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m ai_result = \u001b[43mjudge\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# 正解ラベルの取得\u001b[39;00m\n\u001b[32m    270\u001b[39m correct_label = CORRECT_ANSWERS.get(file_id, \u001b[33m\"\u001b[39m\u001b[33m---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 123\u001b[39m, in \u001b[36mBatchJudge.predict\u001b[39m\u001b[34m(self, video_path)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rotate: frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# YOLOv8による物体検出とトラッキング\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# persist=True にすることで、前後のフレームの同一物体をID管理する\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m curr_ball = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    126\u001b[39m curr_plate = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/baseball_ai/venv/lib/python3.12/site-packages/ultralytics/engine/model.py:578\u001b[39m, in \u001b[36mModel.track\u001b[39m\u001b[34m(self, source, stream, persist, **kwargs)\u001b[39m\n\u001b[32m    576\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# batch-size 1 for tracking in videos\u001b[39;00m\n\u001b[32m    577\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mtrack\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/baseball_ai/venv/lib/python3.12/site-packages/ultralytics/engine/model.py:535\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    534\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/baseball_ai/venv/lib/python3.12/site-packages/ultralytics/engine/predictor.py:225\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/baseball_ai/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:38\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     41\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     42\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/baseball_ai/venv/lib/python3.12/site-packages/ultralytics/engine/predictor.py:336\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[32m2\u001b[39m]:\n\u001b[32m    335\u001b[39m     \u001b[38;5;28mself\u001b[39m.results = \u001b[38;5;28mself\u001b[39m.postprocess(preds, im, im0s)\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_predict_postprocess_end\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[38;5;66;03m# Visualize, save, write results\u001b[39;00m\n\u001b[32m    339\u001b[39m n = \u001b[38;5;28mlen\u001b[39m(im0s)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/baseball_ai/venv/lib/python3.12/site-packages/ultralytics/engine/predictor.py:502\u001b[39m, in \u001b[36mBasePredictor.run_callbacks\u001b[39m\u001b[34m(self, event)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run all registered callbacks for a specific event.\"\"\"\u001b[39;00m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks.get(event, []):\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m     \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/baseball_ai/venv/lib/python3.12/site-packages/ultralytics/trackers/track.py:93\u001b[39m, in \u001b[36mon_predict_postprocess_end\u001b[39m\u001b[34m(predictor, persist)\u001b[39m\n\u001b[32m     90\u001b[39m     predictor.vid_path[i \u001b[38;5;28;01mif\u001b[39;00m is_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m] = vid_path\n\u001b[32m     92\u001b[39m det = (result.obb \u001b[38;5;28;01mif\u001b[39;00m is_obb \u001b[38;5;28;01melse\u001b[39;00m result.boxes).cpu().numpy()\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m tracks = \u001b[43mtracker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43morig_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfeats\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tracks) == \u001b[32m0\u001b[39m:\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/baseball_ai/venv/lib/python3.12/site-packages/ultralytics/trackers/byte_tracker.py:320\u001b[39m, in \u001b[36mBYTETracker.update\u001b[39m\u001b[34m(self, results, img, feats)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgmc\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    318\u001b[39m     \u001b[38;5;66;03m# use try-except here to bypass errors from gmc module\u001b[39;00m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m         warp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgmc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mxyxy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    322\u001b[39m         warp = np.eye(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/baseball_ai/venv/lib/python3.12/site-packages/ultralytics/trackers/utils/gmc.py:109\u001b[39m, in \u001b[36mGMC.apply\u001b[39m\u001b[34m(self, raw_frame, detections)\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_ecc(raw_frame)\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method == \u001b[33m\"\u001b[39m\u001b[33msparseOptFlow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_sparseoptflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.eye(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/baseball_ai/venv/lib/python3.12/site-packages/ultralytics/trackers/utils/gmc.py:294\u001b[39m, in \u001b[36mGMC.apply_sparseoptflow\u001b[39m\u001b[34m(self, raw_frame)\u001b[39m\n\u001b[32m    291\u001b[39m     frame = cv2.resize(frame, (width // \u001b[38;5;28mself\u001b[39m.downscale, height // \u001b[38;5;28mself\u001b[39m.downscale))\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# Find good features to track\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m keypoints = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgoodFeaturesToTrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[38;5;66;03m# Handle first frame initialization\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.initializedFirstFrame \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.prevKeyPoints \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. 設定・パラメータ定義エリア\n",
    "#    ここでの設定値は、物理的な定義や事前の計測に基づいています。\n",
    "# ==============================================================================\n",
    "\n",
    "# 学習済みモデルのパス\n",
    "MODEL_PATH = 'runs/detect/train9/weights/best.pt'\n",
    "# 検証用動画が入っているフォルダ\n",
    "VIDEO_DIR = 'video'\n",
    "# 正解ラベルが書かれたCSVファイル\n",
    "CSV_PATH = 'Label.csv' \n",
    "\n",
    "# --- ストライクゾーン構築のためのパラメータ ---\n",
    "# 根拠: 高校球児の平均身長(約171cm)とホームベース幅(43.2cm)の比率から算出\n",
    "# これにより、カメラの距離が変わっても適切なゾーンを自動生成できます。\n",
    "\n",
    "ZONE_W_RATIO = 1.0         # ゾーン横幅 (ベース幅と同じ)\n",
    "ZONE_H_RATIO = 1.09        # ゾーン高さ (身長の胸〜膝の長さをベース幅で割った値)\n",
    "ZONE_OFFSET_RATIO = 1.03   # ゾーン下限の高さ (地面から膝下までの高さをベース幅で割った値)\n",
    "\n",
    "# --- 判定ロジックのためのパラメータ ---\n",
    "BALL_SIZE_RATIO = 0.18     # 奥行き判定: ボールがベース幅の「0.18倍」になったら通過とみなす\n",
    "IGNORE_TOP_RATIO = 0.2     # 誤検知対策: 画面上部20%（天井など）は無視する\n",
    "STRICT_MODE = False        # 判定モード: Falseなら「ボールが少しかすってもストライク」とする\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. データ読み込み用関数\n",
    "#    CSVの表記ゆれ（1.0, 1, 1.mp4など）を吸収して読み込む処理\n",
    "# ==============================================================================\n",
    "def load_labels(csv_path):\n",
    "    \"\"\"\n",
    "    正解ラベルCSVを読み込み、辞書形式 {ファイルID: 正解ラベル} で返す。\n",
    "    \"\"\"\n",
    "    print(f\"CSV読み込み中: {csv_path}\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(\"【エラー】CSVファイルが見つかりません。\")\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        answers = {}\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            raw_id = row.iloc[0]\n",
    "            label_raw = str(row.iloc[1]).strip().upper()\n",
    "            \n",
    "            # IDの表記ゆれを修正 (例: 1.0 -> 1)\n",
    "            try:\n",
    "                clean_id = str(int(float(raw_id)))\n",
    "            except:\n",
    "                clean_id = str(raw_id).replace('.mp4', '').strip()\n",
    "\n",
    "            # ラベルの表記ゆれを修正\n",
    "            if \"ストライク\" in label_raw: label = \"STRIKE\"\n",
    "            elif \"ボール\" in label_raw: label = \"BALL\"\n",
    "            else: label = label_raw\n",
    "            \n",
    "            answers[clean_id] = label\n",
    "            \n",
    "        print(f\"正解データを {len(answers)} 件読み込みました。\")\n",
    "        return answers\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"【エラー】CSV読み込み中にエラーが発生しました: {e}\")\n",
    "        return {}\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. 判定クラス (BatchJudge)\n",
    "#    1つの動画を受け取り、AI解析を行って結果を返すクラス\n",
    "# ==============================================================================\n",
    "class BatchJudge:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        # ゾーン計算を安定させるための変数\n",
    "        self.plate_width_history = []\n",
    "        self.fixed_plate_width = 0\n",
    "        self.zone_coords = None\n",
    "        \n",
    "        # ボールの動きを追うための変数\n",
    "        self.prev_ball = None\n",
    "        \n",
    "        # 最終結果 (初期値は不明)\n",
    "        self.final_judgment = \"UNKNOWN\"\n",
    "\n",
    "    def predict(self, video_path):\n",
    "        \"\"\"\n",
    "        動画を1フレームずつ読み込み、ストライク/ボールを判定する\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        # 動画のサイズを取得\n",
    "        w_org = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        h_org = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        # スマホ撮影など、縦横が逆転している場合の自動回転判定\n",
    "        if w_org > h_org:\n",
    "            rotate = True\n",
    "            screen_h = w_org # 回転後は幅が高さになる\n",
    "        else:\n",
    "            rotate = False\n",
    "            screen_h = h_org\n",
    "\n",
    "        # 天井照明などの誤検知を防ぐための無視ライン\n",
    "        ignore_y = int(screen_h * IGNORE_TOP_RATIO)\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            \n",
    "            # 回転が必要なら90度回転させる\n",
    "            if rotate: frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "            # YOLOv8による物体検出とトラッキング\n",
    "            # persist=True にすることで、前後のフレームの同一物体をID管理する\n",
    "            results = self.model.track(frame, persist=True, conf=0.15, verbose=False)\n",
    "            \n",
    "            curr_ball = None\n",
    "            curr_plate = None\n",
    "\n",
    "            # 検出結果の解析\n",
    "            if results[0].boxes.id is not None:\n",
    "                boxes = results[0].boxes.xywh.cpu().numpy()\n",
    "                classes = results[0].boxes.cls.cpu().numpy()\n",
    "                \n",
    "                for box, cls_id in zip(boxes, classes):\n",
    "                    bx, by, bw, bh = box\n",
    "                    \n",
    "                    # 画面上部（天井）の検出は無視する\n",
    "                    if by < ignore_y: continue \n",
    "\n",
    "                    # クラス0: ボール\n",
    "                    if int(cls_id) == 0:\n",
    "                        # 複数検出された場合は、最も大きい（手前にある）ボールを採用\n",
    "                        if curr_ball is None or bw > curr_ball[2]:\n",
    "                            curr_ball = box\n",
    "                            \n",
    "                    # クラス1: ホームベース\n",
    "                    elif int(cls_id) == 1:\n",
    "                        if curr_plate is None or bw > curr_plate[2]:\n",
    "                            curr_plate = box\n",
    "\n",
    "            # --- A. ストライクゾーンの動的生成 ---\n",
    "            # ホームベースが検出されていれば、その幅を基準にゾーンを計算する\n",
    "            if curr_plate is not None:\n",
    "                px, py, pw, ph = curr_plate\n",
    "                \n",
    "                # 幅の数値を安定させるために移動平均をとる\n",
    "                self.plate_width_history.append(pw)\n",
    "                if len(self.plate_width_history) > 10: self.plate_width_history.pop(0)\n",
    "                self.fixed_plate_width = sum(self.plate_width_history) / len(self.plate_width_history)\n",
    "\n",
    "                # ベース幅を「定規」としてゾーン座標を計算\n",
    "                base_w = self.fixed_plate_width\n",
    "                zw = int(base_w * ZONE_W_RATIO)\n",
    "                zh = int(zw * ZONE_H_RATIO)\n",
    "                zb = int(py - (base_w * ZONE_OFFSET_RATIO)) # 下限\n",
    "                zt = zb - zh                                # 上限\n",
    "                zx = int(px)\n",
    "                zl, zr = zx - zw//2, zx + zw//2\n",
    "                \n",
    "                self.zone_coords = (zl, zt, zr, zb)\n",
    "\n",
    "            # --- B. 投球判定ロジック ---\n",
    "            # まだ判定が出ておらず、ゾーンが確定している場合に実行\n",
    "            if self.final_judgment == \"UNKNOWN\" and self.zone_coords and self.fixed_plate_width > 0:\n",
    "                \n",
    "                # 判定すべきボールのサイズ（通過基準）を計算\n",
    "                target_w = self.fixed_plate_width * BALL_SIZE_RATIO\n",
    "                \n",
    "                if curr_ball is not None:\n",
    "                    bx, by, bw, bh = curr_ball\n",
    "                    \n",
    "                    # ボールの大きさが基準を超えたら判定を行う\n",
    "                    if bw >= target_w:\n",
    "                        ball_radius = bw / 2\n",
    "                        judge_result = None\n",
    "                        \n",
    "                        # 【重要】補間処理\n",
    "                        # フレーム間でボールが急に大きくなった場合、\n",
    "                        # ちょうど基準サイズになった瞬間の座標を計算して精度を高める\n",
    "                        if self.prev_ball is not None:\n",
    "                            prev_x, prev_y, prev_w, prev_h = self.prev_ball\n",
    "                            if prev_w < target_w:\n",
    "                                # 線形補間により通過座標を推定\n",
    "                                ratio = (target_w - prev_w) / (bw - prev_w)\n",
    "                                cross_y = prev_y + (by - prev_y) * ratio\n",
    "                                cross_x = prev_x + (bx - prev_x) * ratio\n",
    "                                judge_result = self._check_zone(cross_x, cross_y, ball_radius)\n",
    "                            else:\n",
    "                                judge_result = self._check_zone(bx, by, ball_radius)\n",
    "                        else:\n",
    "                            judge_result = self._check_zone(bx, by, ball_radius)\n",
    "                        \n",
    "                        # 判定が出たらループを抜ける（処理高速化のため）\n",
    "                        if judge_result:\n",
    "                            self.final_judgment = judge_result\n",
    "                            break\n",
    "\n",
    "                    self.prev_ball = curr_ball\n",
    "\n",
    "        cap.release()\n",
    "        return self.final_judgment\n",
    "\n",
    "    def _check_zone(self, x, y, radius):\n",
    "        \"\"\"\n",
    "        座標(x,y)がストライクゾーンに入っているか判定する\n",
    "        \"\"\"\n",
    "        zl, zt, zr, zb = self.zone_coords\n",
    "        \n",
    "        # 判定条件\n",
    "        # STRICT_MODEがFalseの場合、ボールの端がかかっていればOKとする\n",
    "        if STRICT_MODE:\n",
    "            is_y_in = (zt <= y <= zb)\n",
    "            is_x_in = (zl <= x <= zr)\n",
    "        else:\n",
    "            is_y_in = (y + radius >= zt) and (y - radius <= zb)\n",
    "            is_x_in = (x + radius >= zl) and (x - radius <= zr)\n",
    "\n",
    "        if is_y_in and is_x_in:\n",
    "            return \"STRIKE\"\n",
    "        else:\n",
    "            return \"BALL\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. メイン実行ブロック\n",
    "#    全動画ファイルを順次読み込み、精度を検証する\n",
    "# ==============================================================================\n",
    "\n",
    "# モデルの読み込み\n",
    "print(f\"モデル読み込み中...: {MODEL_PATH}\")\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(\"モデルが見つかりません\")\n",
    "shared_model = YOLO(MODEL_PATH)\n",
    "\n",
    "# 正解データの読み込み\n",
    "CORRECT_ANSWERS = load_labels(CSV_PATH)\n",
    "\n",
    "# 動画ファイルリストの取得（ファイル名順にソート）\n",
    "video_files = glob.glob(os.path.join(VIDEO_DIR, \"*.mp4\"))\n",
    "video_files.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
    "\n",
    "print(f\"対象動画数: {len(video_files)}本\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'File':<6} | {'AI Pred':<10} | {'Correct':<10} | {'Result'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "correct_count = 0\n",
    "total_checked = 0\n",
    "unknown_count = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 全動画ループ\n",
    "for video_path in video_files:\n",
    "    file_id = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    \n",
    "    # AIによる判定\n",
    "    judge = BatchJudge(shared_model)\n",
    "    ai_result = judge.predict(video_path)\n",
    "    \n",
    "    # 正解ラベルの取得\n",
    "    correct_label = CORRECT_ANSWERS.get(file_id, \"---\")\n",
    "    \n",
    "    status = \"\"\n",
    "    if correct_label != \"---\":\n",
    "        total_checked += 1\n",
    "        if ai_result == correct_label:\n",
    "            status = \"OK\"\n",
    "            correct_count += 1\n",
    "        else:\n",
    "            status = \"NG\"\n",
    "    \n",
    "    if ai_result == \"UNKNOWN\":\n",
    "        unknown_count += 1\n",
    "\n",
    "    # 結果の表示\n",
    "    print(f\"{file_id:<6} | {ai_result:<10} | {correct_label:<10} | {status}\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "# --- 最終結果レポート ---\n",
    "print(\"-\" * 60)\n",
    "print(f\"処理完了 ({elapsed_time:.1f}秒)\")\n",
    "print(f\"判定不能(UNKNOWN): {unknown_count}本\")\n",
    "\n",
    "if total_checked > 0:\n",
    "    accuracy = (correct_count / total_checked) * 100\n",
    "    print(f\"\\n【最終成績】\")\n",
    "    print(f\"正解数: {correct_count} / {total_checked}\")\n",
    "    print(f\"正答率: {accuracy:.1f}%\")\n",
    "else:\n",
    "    print(\"\\n※正解データが見つかりませんでした。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
