# ストライク判定AI（画像解析 × 機械学習）

## 概要
日揮パラレルテクノロジーズ（JPT）体験インターン課題として作成した成果物です。
提供された150データの投球映像をもとに、YOLOを中心とした画像解析とアルゴリズムによるストライク判定モデルを実装しました。

映像からボール軌道・位置を抽出し、ストライクゾーンとの位置関係から自動で『ストライク/ボール」を判定します。
解析内容の詳細は、PDFレポートにまとめています。

## 使用技術
- Python / Jupyter Notebook
- YOLO（v8）：物体検出
- OpenCV（cv2）：画像処理、フレーム解析、ストライクゾーン検出
- Numpy：座標計算、数値処理
- Pandas：ラベルデータ管理、結果の整理
- Make Sense.ai：ボールとホームベース位置のアノテーション
- matplotlib / seaborn：可視化
- glob / os / shutil：データセット整理、ファイル操作
- random：データシャッフル
- time：処理時間の計測

## ディレクトリ構成
本プロジェクトのディレクトリ構成は以下の通りです。  
※学習に使用した「150本の投球動画」および「300枚のボール画像データ」は、非公開データのため本リポジトリには含まれていません。

```text
Baseball_AI/
│
├── 00_homeplate_Data_Preparation.ipynb  # [前処理] 映像からホームベース画像を自動抽出
├── 01_training_ball_AI.ipynb            # [学習] データセット分割・YOLOv8の転移学習
├── 02_run_Baseball_AI.ipynb             # [推論] 全データ(150本)に対する判定と精度算出
│
├── dataset/                    # YOLOv8学習用データセット
│   ├── data.yaml               # データセット設定ファイル
│   ├── train/                  # 学習用データ (80%)
│   │   ├── images/             # 画像ファイル (.jpg)
│   │   └── labels/             # アノテーションファイル (.txt)
│   └── val/                    # 検証用データ (20%) - 層化抽出で分割
│       ├── images/             # 画像ファイル (.jpg)
│       └── labels/             # アノテーションファイル (.txt)
│
├── video/                      # 解析対象の投球映像 (mp4)
├── capture/                    # 教師データ作成用に切り出した画像素材
├── Label.csv                   # 正解ラベル (Ground Truth)
│
├── runs/                       # 学習結果の出力先
│   └── detect/train*/weights/  # 学習済み重みファイル (best.pt)
│
├── yolov8n.pt                  # 事前学習済みモデル
└── requirements.txt            # 実行に必要なライブラリ一覧
```
## プロジェクト概要
1. データセット整備、前処理
2. ストライクゾーンの自動推定
3. ボール軌道と位置推定
4. 精度検証と考察

PDFには、背景、目的、分析フロー、結果、今後の展望を詳細に掲載しています。
